{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jetson Nano code 1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhqUWicYMzwsrV34czLbJP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devsaa05/Inter_2-incubitu/blob/master/Jetson_Nano_code_1_(face_detection).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ucNRACoDg45",
        "colab_type": "text"
      },
      "source": [
        "A simple command-line instruction to check for the camera connection is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpeTASonDjz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        \n",
        "akshay@jetson_nano:~$ ls -l /dev/video0\n",
        "Crw-rw----+ 1 root video 81, 0 Jan 2 14:30 /dev/video0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Yt3-UsDm-q",
        "colab_type": "text"
      },
      "source": [
        "check for the camera connection is to use the GStreamer application gst-launch to launch a display window and confirm that you can see a live stream from the camera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvdChJq5Dul4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "akshay@jetson_nano:~$ gst-launch-1.0 nvarguscamerasrc ! 'video/x-raw(memory:NVMM),width=3820, height=2464, framerate=21/1, format=NV12' ! nvvidconv flip-method=0 ! 'video/x-raw,width=480, height=320' ! nvvidconv ! nvegltransform ! nveglglessink -e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CkZ4HmsDyFQ",
        "colab_type": "text"
      },
      "source": [
        "Use Python in the terminal to confirm OpenCV installation and its version.\n",
        "\n",
        "        \n",
        "akshay@jetson_nano:~$ python\n",
        "Python 2.7.15+ (default, Oct 7 2019, 17:39:04)\n",
        "[GCC 7.4.0] on linux2\n",
        "Type “help”, “copyright”, “credits” or “license”, for more information\n",
        ">>>import cv2\n",
        ">>> cv2.__version__\n",
        "‘3.3.1’\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH1K8K5CD2qJ",
        "colab_type": "text"
      },
      "source": [
        "Simple Python Application for Face Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbLV9WtID7EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "HAAR_CASCADE_XML_FILE_FACE = \"/usr/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "\n",
        "GSTREAMER_PIPELINE = 'nvarguscamerasrc ! video/x-raw(memory:NVMM), width=3280, height=2464, format=(string)NV12, framerate=21/1 ! nvvidconv flip-method=0 ! video/x-raw, width=960, height=616, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink'\n",
        "\n",
        "def faceDetect():\n",
        "    # Obtain face detection Haar cascade XML files from OpenCV\n",
        "    face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_XML_FILE_FACE)\n",
        "\n",
        "    # Video Capturing class from OpenCV\n",
        "    video_capture = cv2.VideoCapture(GSTREAMER_PIPELINE, cv2.CAP_GSTREAMER)\n",
        "    if video_capture.isOpened():\n",
        "        cv2.namedWindow(\"Face Detection Window\", cv2.WINDOW_AUTOSIZE)\n",
        "\n",
        "        while True:\n",
        "            return_key, image = video_capture.read()\n",
        "            if not return_key:\n",
        "                break\n",
        "\n",
        "            grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            detected_faces = face_cascade.detectMultiScale(grayscale_image, 1.3, 5)\n",
        "\n",
        "            # Create rectangle around the face in the image canvas\n",
        "            for (x_pos, y_pos, width, height) in detected_faces:\n",
        "                cv2.rectangle(image, (x_pos, y_pos), (x_pos + width, y_pos + height), (0, 0, 0), 2)\n",
        "\n",
        "            cv2.imshow(\"Face Detection Window\", image)\n",
        "\n",
        "            key = cv2.waitKey(30) & 0xff\n",
        "            # Stop the program on the ESC key\n",
        "            if key == 27:\n",
        "                break\n",
        "\n",
        "        video_capture.release()\n",
        "        cv2.destroyAllWindows()\n",
        "    else:\n",
        "        print(\"Cannot open Camera\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    faceDetect()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIOeTX-EEWOA",
        "colab_type": "text"
      },
      "source": [
        "**code discription :-**\n",
        "\n",
        "The code basically uses pre-trained Haar Cascade implementations stored in the OpenCV library. As mentioned earlier, the code uses the GStreamer pipeline to create an interface between the camera and the OS. The pipeline is used to create a VideoCapture() object.\n",
        "\n",
        "Each image frame from the camera live stream is processed and tested for face detection. The code implements an additional step of converting the color image to a grayscale image since the color does not determine the facial features. This avoids computational overheads and enhances performance. Once confirmed if the image contains a human face, a rectangle is drawn around the boundaries.\n",
        "\n",
        "**Results and Conclusions :- **\n",
        "\n",
        "The Jetson Nano developer kit is a powerful platform but still prone to unoptimized code and routines. A low FPS of 10 was used to avoid computational load. This Haar Cascade based implementation is a rudimentary algorithm for face detection and several advanced machine learning algorithms have been developed since. Also, this implementation does not salvage the GPU available on Jetson Nano.\n",
        "The next step to learn basic implementations of CUDA-based parallel programming on Jetson Nano and then a deep learning-based solution for face/object detection using TensorRT on the Jetson Nano GPU. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dll-bxxsFTeR",
        "colab_type": "text"
      },
      "source": [
        "**OR you can use given code too**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTwNzUi7FYs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# gstreamer_pipeline returns a GStreamer pipeline for capturing from the CSI camera\n",
        "# Defaults to 1280x720 @ 30fps\n",
        "# Flip the image by setting the flip_method (most common values: 0 and 2)\n",
        "# display_width and display_height determine the size of the window on the screen\n",
        "\n",
        "\n",
        "def gstreamer_pipeline(\n",
        "    capture_width=3280,\n",
        "    capture_height=2464,\n",
        "    display_width=820,\n",
        "    display_height=616,\n",
        "    framerate=21,\n",
        "    flip_method=0,\n",
        "):\n",
        "    return (\n",
        "        \"nvarguscamerasrc ! \"\n",
        "        \"video/x-raw(memory:NVMM), \"\n",
        "        \"width=(int)%d, height=(int)%d, \"\n",
        "        \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
        "        \"nvvidconv flip-method=%d ! \"\n",
        "        \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
        "        \"videoconvert ! \"\n",
        "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
        "        % (\n",
        "            capture_width,\n",
        "            capture_height,\n",
        "            framerate,\n",
        "            flip_method,\n",
        "            display_width,\n",
        "            display_height,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def face_detect():\n",
        "    face_cascade = cv2.CascadeClassifier(\n",
        "        \"/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "    )\n",
        "    eye_cascade = cv2.CascadeClassifier(\n",
        "        \"/usr/share/opencv4/haarcascades/haarcascade_eye.xml\"\n",
        "    )\n",
        "    cap = cv2.VideoCapture(gstreamer_pipeline(), cv2.CAP_GSTREAMER)\n",
        "    if cap.isOpened():\n",
        "        cv2.namedWindow(\"Face Detect\", cv2.WINDOW_AUTOSIZE)\n",
        "        while cv2.getWindowProperty(\"Face Detect\", 0) >= 0:\n",
        "            ret, img = cap.read()\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "            for (x, y, w, h) in faces:\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "                roi_gray = gray[y : y + h, x : x + w]\n",
        "                roi_color = img[y : y + h, x : x + w]\n",
        "                eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "                for (ex, ey, ew, eh) in eyes:\n",
        "                    cv2.rectangle(\n",
        "                        roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2\n",
        "                    )\n",
        "\n",
        "            cv2.imshow(\"Face Detect\", img)\n",
        "            keyCode = cv2.waitKey(30) & 0xFF\n",
        "            # Stop the program on the ESC key\n",
        "            if keyCode == 27:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "    else:\n",
        "        print(\"Unable to open camera\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    face_detect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8C2ivegFtF5",
        "colab_type": "text"
      },
      "source": [
        "**Code for camera checking camera status**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txQxYAd4FzFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using a CSI camera (such as the Raspberry Pi Version 2) connected to a\n",
        "# NVIDIA Jetson Nano Developer Kit using OpenCV\n",
        "# Drivers for the camera and OpenCV are included in the base image\n",
        "\n",
        "import cv2\n",
        "\n",
        "# gstreamer_pipeline returns a GStreamer pipeline for capturing from the CSI camera\n",
        "# Defaults to 1280x720 @ 60fps\n",
        "# Flip the image by setting the flip_method (most common values: 0 and 2)\n",
        "# display_width and display_height determine the size of the window on the screen\n",
        "\n",
        "\n",
        "def gstreamer_pipeline(\n",
        "    capture_width=1280,\n",
        "    capture_height=720,\n",
        "    display_width=1280,\n",
        "    display_height=720,\n",
        "    framerate=60,\n",
        "    flip_method=0,\n",
        "):\n",
        "    return (\n",
        "        \"nvarguscamerasrc ! \"\n",
        "        \"video/x-raw(memory:NVMM), \"\n",
        "        \"width=(int)%d, height=(int)%d, \"\n",
        "        \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
        "        \"nvvidconv flip-method=%d ! \"\n",
        "        \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
        "        \"videoconvert ! \"\n",
        "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
        "        % (\n",
        "            capture_width,\n",
        "            capture_height,\n",
        "            framerate,\n",
        "            flip_method,\n",
        "            display_width,\n",
        "            display_height,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def show_camera():\n",
        "    # To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
        "    print(gstreamer_pipeline(flip_method=0))\n",
        "    cap = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
        "    if cap.isOpened():\n",
        "        window_handle = cv2.namedWindow(\"CSI Camera\", cv2.WINDOW_AUTOSIZE)\n",
        "        # Window\n",
        "        while cv2.getWindowProperty(\"CSI Camera\", 0) >= 0:\n",
        "            ret_val, img = cap.read()\n",
        "            cv2.imshow(\"CSI Camera\", img)\n",
        "            # This also acts as\n",
        "            keyCode = cv2.waitKey(30) & 0xFF\n",
        "            # Stop the program on the ESC key\n",
        "            if keyCode == 27:\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "    else:\n",
        "        print(\"Unable to open camera\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    show_camera()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}