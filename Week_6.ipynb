{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 6",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMS9CaxlfA2jeVE3BLWFsCK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devsaa05/Inter_2-incubitu/blob/master/Week_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk2QmfV5jrN5",
        "colab_type": "text"
      },
      "source": [
        "Working code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoaYqTLUfqrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "28a8f81d-e575-4291-9e33-5902be92d918"
      },
      "source": [
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "\n",
        "picture_of_me = face_recognition.load_image_file(\"/content/donald.jpg\")\n",
        "my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n",
        "\n",
        "# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\n",
        "\n",
        "unknown_picture = face_recognition.load_image_file(\"/content/test.jpg\")\n",
        "unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n",
        "\n",
        "# Now we can see the two face encodings are of the same person with `compare_faces`!\n",
        "\n",
        "results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n",
        "\n",
        "if results[0] == True:\n",
        "    print(\"It's a picture of me!\")\n",
        "else:\n",
        "    print(\"It's not a picture of me!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "It's a picture of me!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIWYBjqpgGOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "7de2fe82-0e21-4110-acf6-60942e82929c"
      },
      "source": [
        "# module and library required to build a Face Recognition System\n",
        "import face_recognition\n",
        "import cv2\n",
        "\n",
        "# objective: this code will help you in running face recognition on a video file and saving the results to a new video file.\n",
        "\n",
        "# Open the input movie file\n",
        "# \"VideoCapture\" is a class for video capturing from video files, image sequences or cameras\n",
        "\n",
        "input_video = cv2.VideoCapture(\"/content/face.mp4\")\n",
        "\n",
        "#\"CAP_PROP_FRAME_COUNT\": it helps in finding number of frames in the video file.\n",
        "\n",
        "length = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Create an output movie file (make sure resolution/frame rate matches input video!)\n",
        "#  So we capture a video, process it frame-by-frame and we want to save that video, it only possible by using \"VideoWriter\" object\n",
        "# FourCC is a 4-byte code used to specify the video codec. The list of available codes can be found in fourcc.org. It is platform dependent.\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc('M','P','E','G')\n",
        "\n",
        "# 25.07-  number of frames per second (fps)\n",
        "#(1280,720)- frame size\n",
        "\n",
        "output_video = cv2.VideoWriter('output.avi', fourcc, 25.07, (1280, 720))\n",
        "\n",
        "# Load some sample pictures and learn how to recognize them.\n",
        "female_image = face_recognition.load_image_file(\"/content/bill.jpg\")\n",
        "female_face_encoding = face_recognition.face_encodings(female_image)[0]\n",
        "\n",
        "#  \"face_recognition.face_encodings\": it's a face_recognition package which returns a list of 128-dimensional face encodings\n",
        "\n",
        "male_image = face_recognition.load_image_file(\"/content/donald.jpg\")\n",
        "male_face_encoding = face_recognition.face_encodings(male_image)[0]\n",
        "\n",
        "\n",
        "known_faces = [\n",
        "    female_face_encoding,\n",
        "    male_face_encoding\n",
        "]\n",
        "\n",
        "# Initialize some variables\n",
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "frame_number = 0\n",
        "\n",
        "while True:\n",
        "    # Grab a single frame of video\n",
        "    ret, frame = input_video.read()\n",
        "    frame_number += 1\n",
        "\n",
        "# Quit when the input video file ends\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "# Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "# Find all the faces and face encodings in the current frame of video\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "face_names = []\n",
        "    for (face_encoding in face_encodings):\n",
        "        # See if the face is a match for the known face(s)\n",
        "        match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n",
        "\n",
        "\n",
        "        name = None\n",
        "        if match[0]:\n",
        "            name = \"bill\"\n",
        "        elif match[1]:\n",
        "            name = \"donald\"\n",
        "\n",
        "face_names.append(name)\n",
        "\n",
        "# Label the results\n",
        "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
        "        if not name:\n",
        "            continue\n",
        "\n",
        "# Draw a box around the face\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "\n",
        "# Draw a label with a name below the face\n",
        "        cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "# Write the resulting image to the output video file\n",
        "    print(\"Writing frame {} / {}\".format(frame_number, length))\n",
        "    output_video.write(frame)\n",
        "\n",
        "# All done!\n",
        "input_video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-59bb83c326ae>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    for (face_encoding in face_encodings):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Elt2tLNhTZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "5f2bae2e-752f-4433-bf20-02d77eff137a"
      },
      "source": [
        "!pip install face_recognition\n",
        "\n",
        "# import the libraries\n",
        "import os\n",
        "import face_recognition\n",
        "\n",
        "# make a list of all the available images\n",
        "images = os.listdir('images')\n",
        "\n",
        "images = ['/content/bill.jpg', '/content/donald.jpg', '/content/elon.jpg', '/content/jeff.jpg', '/content/obama.jpg']\n",
        "\n",
        "# load your image\n",
        "image_to_be_matched = face_recognition.load_image_file('/content/0.jpg')\n",
        "\n",
        "# encoded the loaded image into a feature vector\n",
        "\n",
        "image_to_be_matched_encoded = face_recognition.face_encodings(\n",
        "\n",
        "    image_to_be_matched)[0]\n",
        "\n",
        "# iterate over each image\n",
        "for image in images:\n",
        "    # load the image\n",
        "    current_image = face_recognition.load_image_file(\"images/\" + image)\n",
        "\n",
        "    # encode the loaded image into a feature vector\n",
        "    current_image_encoded = face_recognition.face_encodings(current_image)[0]\n",
        "\n",
        "    # match your image with the image and check if it matches\n",
        "    result = face_recognition.compare_faces(\n",
        "        [image_to_be_matched_encoded], current_image_encoded)\n",
        "\n",
        "    # check if it was a match\n",
        "    if result[0] == True:\n",
        "        print (\"Matched: \" + image)\n",
        "    else:\n",
        "        print (\"Not matched: \" + image)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e7f76b7779e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# make a list of all the available images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'/content/bill.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/donald.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/elon.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/jeff.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/obama.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images'"
          ]
        }
      ]
    }
  ]
}